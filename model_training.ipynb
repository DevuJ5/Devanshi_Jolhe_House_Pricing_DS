{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055e47ae-0b6e-4276-97b2-319763256c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7edb36d-0088-42d9-9937-1ee7cc6b292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = Path(\"../data/raw/train(1).xlsx\")\n",
    "IMG_TRAIN_DIR = Path(\"../data/images/train\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784334fd-37b6-4420-8f35-df02d9bb06c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (16209, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9117000170</td>\n",
       "      <td>20150505T000000</td>\n",
       "      <td>268643</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1810</td>\n",
       "      <td>9240</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1810</td>\n",
       "      <td>0</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>98055</td>\n",
       "      <td>47.4362</td>\n",
       "      <td>-122.187</td>\n",
       "      <td>1660</td>\n",
       "      <td>9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6700390210</td>\n",
       "      <td>20140708T000000</td>\n",
       "      <td>245000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2788</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0</td>\n",
       "      <td>98031</td>\n",
       "      <td>47.4034</td>\n",
       "      <td>-122.187</td>\n",
       "      <td>1720</td>\n",
       "      <td>3605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7212660540</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>200000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1720</td>\n",
       "      <td>8638</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1720</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.2704</td>\n",
       "      <td>-122.313</td>\n",
       "      <td>1870</td>\n",
       "      <td>7455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8562780200</td>\n",
       "      <td>20150427T000000</td>\n",
       "      <td>352499</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1240</td>\n",
       "      <td>705</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1150</td>\n",
       "      <td>90</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5321</td>\n",
       "      <td>-122.073</td>\n",
       "      <td>1240</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7760400350</td>\n",
       "      <td>20141205T000000</td>\n",
       "      <td>232000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1280</td>\n",
       "      <td>13356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3715</td>\n",
       "      <td>-122.074</td>\n",
       "      <td>1590</td>\n",
       "      <td>8071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date   price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  9117000170  20150505T000000  268643         4       2.25         1810   \n",
       "1  6700390210  20140708T000000  245000         3       2.50         1600   \n",
       "2  7212660540  20150115T000000  200000         4       2.50         1720   \n",
       "3  8562780200  20150427T000000  352499         2       2.25         1240   \n",
       "4  7760400350  20141205T000000  232000         3       2.00         1280   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      9240     2.0           0     0  ...      7        1810              0   \n",
       "1      2788     2.0           0     0  ...      7        1600              0   \n",
       "2      8638     2.0           0     0  ...      8        1720              0   \n",
       "3       705     2.0           0     0  ...      7        1150             90   \n",
       "4     13356     1.0           0     0  ...      7        1280              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1961             0    98055  47.4362 -122.187           1660   \n",
       "1      1992             0    98031  47.4034 -122.187           1720   \n",
       "2      1994             0    98003  47.2704 -122.313           1870   \n",
       "3      2009             0    98027  47.5321 -122.073           1240   \n",
       "4      1994             0    98042  47.3715 -122.074           1590   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        9240  \n",
       "1        3605  \n",
       "2        7455  \n",
       "3         750  \n",
       "4        8071  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(TRAIN_PATH)\n",
    "print(\"Loaded:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266b8b93-cd90-47be-a7e9-6cc0ae1cfd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular numeric columns: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only numeric columns for a clean baseline multimodal model\n",
    "drop_cols = [\"price\", \"id\"]\n",
    "tab_cols = [c for c in df.columns if c not in drop_cols]\n",
    "tab_cols = [c for c in tab_cols if np.issubdtype(df[c].dtype, np.number)]\n",
    "\n",
    "print(\"Tabular numeric columns:\", len(tab_cols))\n",
    "tab_cols[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba28fa2-3063-437b-b795-5d818f0847ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (12967, 21)\n",
      "Val size: (3242, 21)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_df[tab_cols] = scaler.fit_transform(train_df[tab_cols])\n",
    "val_df[tab_cols]   = scaler.transform(val_df[tab_cols])\n",
    "\n",
    "print(\"Train size:\", train_df.shape)\n",
    "print(\"Val size:\", val_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb061c4a-4c7e-4e5b-856d-b27abcb3ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, tabular_cols, target_col=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.tabular_cols = tabular_cols\n",
    "        self.target_col = target_col\n",
    "\n",
    "        self.tf = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        pid = row[\"id\"]\n",
    "\n",
    "        img_path = self.image_dir / f\"{pid}.png\"\n",
    "        if img_path.exists():\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "            except Exception:\n",
    "                img = Image.new(\"RGB\", (224, 224), color=(0, 0, 0))\n",
    "        else:\n",
    "            img = Image.new(\"RGB\", (224, 224), color=(0, 0, 0))\n",
    "\n",
    "        img = self.tf(img)\n",
    "\n",
    "        tab = row[self.tabular_cols].values.astype(np.float32)\n",
    "        tab = torch.from_numpy(tab)\n",
    "\n",
    "        if self.target_col is not None:\n",
    "            y = np.log1p(float(row[self.target_col]))\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "            return img, tab, y\n",
    "\n",
    "        return img, tab, pid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9497d588-498f-403e-b7c2-586cdb155ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 406\n",
      "Val batches: 102\n"
     ]
    }
   ],
   "source": [
    "train_ds = HouseDataset(train_df, IMG_TRAIN_DIR, tab_cols, target_col=\"price\")\n",
    "val_ds   = HouseDataset(val_df, IMG_TRAIN_DIR, tab_cols, target_col=\"price\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Val batches:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ae9727-859b-4358-9d1d-912b06fc52ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionRegressor(\n",
      "  (cnn): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (tab_mlp): TabularMLP(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=18, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (4): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.25, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class TabularMLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class FusionRegressor(nn.Module):\n",
    "    def __init__(self, tab_in, img_emb_dim=512, tab_emb_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.cnn = backbone\n",
    "\n",
    "        self.tab_mlp = TabularMLP(tab_in, hidden=tab_emb_dim)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(img_emb_dim + tab_emb_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        img_feat = self.cnn(img)\n",
    "        tab_feat = self.tab_mlp(tab)\n",
    "        fused = torch.cat([img_feat, tab_feat], dim=1)\n",
    "        out = self.head(fused).squeeze(1)\n",
    "        return out\n",
    "\n",
    "model = FusionRegressor(tab_in=len(tab_cols)).to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc3344b-8e5d-4c20-9e7e-05f0cf75a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518cb98-93aa-46e9-b973-896ad7758a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3  # demonstration training for notebook\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for img, tab, y in train_loader:v\n",
    "        img, tab, y = img.to(DEVICE), tab.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        pred = model(img, tab)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, tab, y in val_loader:\n",
    "            img, tab = img.to(DEVICE), tab.to(DEVICE)\n",
    "            pred = model(img, tab).cpu().numpy()\n",
    "\n",
    "            ys.append(y.numpy())\n",
    "            ps.append(pred)\n",
    "\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_pred = np.concatenate(ps)\n",
    "    val_rmse = rmse(y_true, y_pred)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | TrainLoss={np.mean(train_losses):.4f} | Val RMSE(log)={val_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462b3b4-fb4a-4bbb-af8e-6e61ecb5b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = Path(\"../outputs/models/notebook_multimodal.pt\")\n",
    "CKPT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"scaler_mean\": scaler.mean_,\n",
    "    \"scaler_scale\": scaler.scale_,\n",
    "    \"tab_cols\": tab_cols\n",
    "}, CKPT_PATH)\n",
    "\n",
    "print(\"Saved checkpoint:\", CKPT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
